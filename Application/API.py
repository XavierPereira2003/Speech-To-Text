import nltk
import librosa
import torch
import soundfile as sf
from transformers import Wav2Vec2ForCTC,Wav2Vec2Tokenizer
import evaluate
nltk.download('punkt')

def load_model():
    """
    Returns the Wav2Vec2 tokienizer and the model from pretrained tokinezer model
    """
    tokienizer=Wav2Vec2Tokenizer.from_pretrained('facebook/wav2vec2-base-960h')
    model=Wav2Vec2ForCTC.from_pretrained("facebook/wav2vec2-base-960h")
    return tokienizer, model

def Correction(input_text:str):
    """
    Returns the input text with correction

    Args:
        input_text (str): Original text generated by the model
    """
    sentence=nltk.sent_tokenize(input_text)
    return (" ".join([s.replace(s[0],s[0].capitalize(),1) for s in sentence]))

def transcribe(tokenizer,model,input_file):
    """
    Returns the transcribe text of the audio

    Args:
        tokiener (_type_): _description_
        model (_type_): _description_
        input_file (_type_): _description_
    """

    speech, sample_rate=sf.read(input_file)

    if len(speech.shape)>1:
        speech=speech[:,0]+speech[:,1]
    
    if sample_rate!=16000:
        speech=librosa.resample(speech,orig_sr=sample_rate,target_sr=16000)
    
    
    input_values = tokenizer(speech, return_tensors="pt").input_values
    logits=model(input_values).logits

    predicted_ids=torch.argmax(logits,dim=-1)

    transcription=tokenizer.decode(predicted_ids[0])

    transcription=Correction(transcription.lower())
    return transcription